{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert mp4/mov video data to jpg/png images and npy binary format for computer vision applications\n",
    "\n",
    "This notebook contains the functions and workflow to process mp4/mov video data into conventional imagery datasets (jpg/png) for deep learning computer vision model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull data from aws_s3 to aws_sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ aws s3 cp s3://bucket-name/folder-name/ ./folder-name-desintation/  --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull data from aws_s3 to local location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes aws env is configured with 2 keys, using aws_cli, boto3\n",
    "# ! aws s3 --no-verify-ssl sync s3://bucket-name ./folder-name-destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general utililty fxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for folder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_ifnotexist(name_folder):\n",
    "    '''\n",
    "    Creates folder with name stored in name_folder. \n",
    "    Can also pass path as name_folder and entire path is created starting\n",
    "                from executing location\n",
    "                \n",
    "    Parameters\n",
    "    ----------\n",
    "    name_folder: String. The name of the folder or folder-path to be created\n",
    "    \n",
    "    '''\n",
    "    exists_chk = os.path.exists(name_folder) # boolean\n",
    "    \n",
    "    if not exists_chk:\n",
    "        # directory does not exist, create it\n",
    "        os.makedirs(name_folder)\n",
    "        print('Created directory: ' + name_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_folder_ifnotexist('test4/test5/test_folder_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp4 to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp4_to_jpg(mp4_folder , mp4_files, jpg_folder, label_to_prepend):\n",
    "    '''\n",
    "    Converts specified mp4 video files into jpg images, \n",
    "    and prepends a specified class label to each image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mp4_folder: String. The path to the folder containing the mp4 video files to be converted\n",
    "    \n",
    "    mp4_files: String. The specific mp4 files inside the specified mp4_folder to be converted to jpg images\n",
    "    \n",
    "    jpg_folder: String. The destination folder for the created jpg files.\n",
    "    \n",
    "    label_to_prepend: String. The  class label to add at the start of each jpg file's name. Example '1_'\n",
    "                      to indicate the given jpg image belongs to class 1. \n",
    "    '''\n",
    "    for mp4 in mp4_files:\n",
    "        cam = cv2.VideoCapture(mp4_folder + mp4)\n",
    "        mp4_name = mp4[:-4] # remove .mp4 from file name\n",
    "        try:\n",
    "            # creating a folder named data\n",
    "            #if not os.path.exists('data'):\n",
    "            if not os.path.exists(jpg_folder):\n",
    "                #os.makedirs('data')\n",
    "                os.makedirs(jpg_folder)\n",
    "\n",
    "        # if not created then raise error\n",
    "        except OSError:\n",
    "            print ('Error: Creating directory of data')\n",
    "\n",
    "        # frame\n",
    "        currentframe = 0\n",
    "\n",
    "        while(True):\n",
    "            # reading from frame\n",
    "            ret,frame = cam.read()\n",
    "            if ret:\n",
    "                # if video is still left continue creating images\n",
    "                #name = './data/frame' + str(currentframe) + '.jpg'\n",
    "                #name = './data/' + str(label_to_prepend) + '_' + 'frame' + str(currentframe) + '_' + mp4_name + '.jpg'\n",
    "                name = './' + jpg_folder + '/' + str(label_to_prepend) + '_' + 'frame' +  str(currentframe) + '_' + mp4_name + '.jpg'\n",
    "                print ('Creating...' + name)\n",
    "\n",
    "                # writing the extracted images\n",
    "                cv2.imwrite(name, frame)\n",
    "\n",
    "                # increasing counter so that it will\n",
    "                # show how many frames are created\n",
    "                currentframe += 1\n",
    "            else:\n",
    "                break\n",
    "        # Release all space and windows once done\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp4_folder = '../data_mp4/'\n",
    "\n",
    "#mp4_files = ['mp4_file1.mp4', # if want to select mp4 file\n",
    "#             'mp4_file2.mp4'\n",
    "#            ]\n",
    "\n",
    "mp4_files = os.listdir(mp4_folder) # if want to convert all mp4 files in a directory\n",
    "\n",
    "jpg_folder = mp4_files[0] + '_jpgs'\n",
    "#jpg_folder = 'practice1' + '_jpgs'\n",
    "\n",
    "label_to_prepend = '0'\n",
    "#label_to_prepend = '1'\n",
    "\n",
    "print(mp4_folder)\n",
    "print(mp4_files)\n",
    "print(\" \")\n",
    "print(jpg_folder)\n",
    "print(label_to_prepend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mp4_to_jpg(mp4_folder, mp4_files, jpg_folder=jpg_folder, label_to_prepend=label_to_prepend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepend class label to already existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_pics(ls_files, path_old, path_new):\n",
    "    '''\n",
    "    Prepends (adds) a class label indication before the name of each jpg file and writes the renamed\n",
    "    jpg files to a new folder location\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ls_files: List. List of jpg files to rename\n",
    "    \n",
    "    path_old: String. Path to the folder containing jpg images with original names\n",
    "    \n",
    "    path_new: String. Path to a the folder where the re-names jpg image files will be saved\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Usage Note: Must comment out and in code lines below based on what naming needs to happen.\n",
    "    Future plan is to make these processes automatic (less hand manip of fxns).\n",
    "    '''\n",
    "    for file in ls_files:\n",
    "        #os.rename(path_old + file, './temp_rename/' + '1_' + file)\n",
    "        \n",
    "        #os.rename(path_old + file,  path_new + '0_' + file)\n",
    "        os.rename(path_old + file,  path_new + '1_' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = '../data_raw_synth_tray_miss_SK-J350-BKT-9080-bad/'\n",
    "data_1 = '../data_raw_synth_tray_full_SK-J350-BKT-9080/'\n",
    "\n",
    "ls_files_0 = os.listdir(data_0)\n",
    "ls_files_1 = os.listdir(data_1)\n",
    "\n",
    "print(len(ls_files_0))\n",
    "print(len(ls_files_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename_pics(ls_files_0, data_0, './temp_rename/')\n",
    "rename_pics(ls_files_1, data_1, './temp_rename/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 12/12/2022\n",
    "from PIL import ImageOps # for greyscale, 4 color channel, issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(path_orig_img, path_smaller_img, x_dim, y_dim, img_quality):\n",
    "    '''\n",
    "    Changes the resolution of jpg or png images\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_orig_img: String. Path to the folder containing the full resolution images (jpg or png).\n",
    "    \n",
    "    path_smaller_img: String. Path to the folder where the reduced-resolution images will be written. \n",
    "    \n",
    "    x_dim: Integer. The x-dimension of the reduced resolution images\n",
    "    \n",
    "    y_dim: Integer. The y-dimension of the reduced resolution images.\n",
    "    \n",
    "    image_quaity: Integer. The value of the 'quality' parameter from the Pillow (PIL) Python library. \n",
    "                  See:  See: https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html\n",
    "                  The image quality, on a scale from 0 (worst) to 95 (best), or the string keep. \n",
    "                  The default is 75. Values above 95 should be avoided; 100 disables portions of \n",
    "                  the JPEG compression algorithm, and results in large files with hardly any gain in image quality. \n",
    "                  The value keep is only valid for JPEG files and will retain the original image quality level, \n",
    "                  subsampling, and qtables.   \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Creates path_smaller_img if it does not exist\n",
    "    '''\n",
    "    \n",
    "    images = [file for file in os.listdir(path_orig_img) if file.endswith(('jpeg', 'png', 'jpg'))]\n",
    "    print('image count for size reduction is: ' + str(len(images)))\n",
    "    \n",
    "    create_folder_ifnotexist(path_smaller_img)\n",
    "    \n",
    "    for image in images:\n",
    "        img = Image.open(path_orig_img + image)\n",
    "        # img.thumbnail((28,28)) # maintains aspect ratio\n",
    "        img = img.resize((x_dim,y_dim)) # disregards original aspect ratio\n",
    "        img.save(('./' + path_smaller_img + '/' + image), \n",
    "                 optimize=True, quality=img_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 299\n",
    "y_dim = 299\n",
    "img_quality = 95\n",
    "\n",
    "path_orig_img = './path_to_full_resolution_images/'\n",
    "\n",
    "path_smaller_img = path_orig_img[:-1] + '_' + str(x_dim) + '/'\n",
    "path_smaller_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resize_images(path_orig_img, path_smaller_img, x_dim, y_dim, img_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create combined folder of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data_sources(ls_source, ls_files_cnt, folder_combined):\n",
    "    '''\n",
    "    A convenience function to copy images from 2 folders into 1 folder location. \n",
    "    Saves the need to copy and combine the images files by hand.\n",
    "    Also allows easy specification of the number of images files (jpg or png) to copy from each folder,\n",
    "        allowing the composition of the training dataset to be customized as needed.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ls_source: List of Strings. The paths to the folders containing the original images that are to be combined.\n",
    "    \n",
    "    ls_files_cnt: List of Integers. Integers specifying how many images to take from each folder specified in ls_source.\n",
    "                  The specified number of images will be randomly selected from the source folder, without replacement.\n",
    "    \n",
    "    folder_combined: String. The base name of the folder the images will be compied to, the folder containing the combined \n",
    "                     image dataset. A timestamp is appended to the final folder name. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    folder_combined_name. String. The name of the folder containing the combined image dataset, with epoch timestamp appended.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Note: len(ls_source) should match len(ls_files_cnt). (note: code a test for this condition and return error if not true).\n",
    "    \n",
    "    Note: Specified number of images will be randomly selected from the source folder, without replacement.\n",
    "    '''\n",
    "    \n",
    "    folder_combined_name = folder_combined  + '_' + str(round(time.time()))\n",
    "    create_folder_ifnotexist(folder_combined_name)\n",
    "    \n",
    "    for i in range(0, len(ls_source)):\n",
    "        ls_files = []\n",
    "        ls_files = os.listdir(ls_source[i])\n",
    "        ls_files_sel = random.sample(ls_files, ls_files_cnt[i])\n",
    "        \n",
    "        for file_name in ls_files_sel:\n",
    "            shutil.copy(ls_source[i] + file_name, folder_combined_name + '/' + file_name)\n",
    "        \n",
    "        #shutil.copy()\n",
    "    #return ls_files_sel    \n",
    "    \n",
    "    return folder_combined_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_source = ['./source_folder_1/',\n",
    "             './source_folder_2/',\n",
    "             './source_folder_3/'\n",
    "             ]\n",
    "ls_files_cnt = [100,\n",
    "                50,\n",
    "                50\n",
    "               ]\n",
    "\n",
    "folder_combined = 'combined_practice1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_combined_name = combine_data_sources(ls_source, \n",
    "                                            ls_files_cnt, \n",
    "                                            folder_combined)\n",
    "folder_combined_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could use a dictionary too, like below (but seemed slightly more complex)\n",
    "# # https://stackoverflow.com/questions/4326658/how-to-index-into-a-dictionary\n",
    "#dict_source = {'./source_folder_1/': 100,\n",
    "#               './source_folder_2/': 100,\n",
    "#             }\n",
    "#print(list(dict_source)[0])\n",
    "#print(list(dict_source.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jpg to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (imports below work in base_env on dsk3)\n",
    "import glob\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_npy(IMAGE_PATH, TRAIN_TEST_SPLIT_RATIO):\n",
    "    '''\n",
    "    Converts image files (jpg or png) to numpy binary numeric format and saves\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    IMAGE_PATH: String. \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Currently writes npy data to local folder\n",
    "    '''\n",
    "    file_paths = glob.glob(path.join(IMAGE_PATH, '*.jpg'))\n",
    "    #file_paths = glob.glob(path.join(IMAGE_PATH, '*.png'))\n",
    "    # Load the images\n",
    "    images = [imageio.imread(path) for path in file_paths]\n",
    "    images = np.asarray(images)\n",
    "    print(images.shape)\n",
    "    \n",
    "    # Scale\n",
    "    images = images / 255\n",
    "    \n",
    "    # Read the labels from the filenames\n",
    "    n_images = images.shape[0]\n",
    "    labels = np.zeros(n_images)\n",
    "    for i in range(n_images):\n",
    "        filename = path.basename(file_paths[i])[0]\n",
    "        labels[i] = int(filename[0])\n",
    "        \n",
    "    ## Split into test and training sets\n",
    "    \n",
    "    # Split at the given index\n",
    "    split_index = int(TRAIN_TEST_SPLIT_RATIO * n_images)\n",
    "    shuffled_indices = np.random.permutation(n_images)\n",
    "    train_indices = shuffled_indices[0:split_index]\n",
    "    test_indices = shuffled_indices[split_index:]\n",
    "    \n",
    "    # Split the images and the labels\n",
    "\n",
    "    X_train = images[train_indices, :, :, :]\n",
    "    #X_train = images[train_indices]\n",
    "    \n",
    "    y_train = labels[train_indices]\n",
    "    \n",
    "    X_test = images[test_indices, :, :, :]\n",
    "    #X_test = images[test_indices]\n",
    "\n",
    "    y_test = labels[test_indices]\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    print(y_train[0:10])\n",
    "    \n",
    "    time_stamp = str(round(time.time()))\n",
    "    \n",
    "    #np.save('X_train.npy', X_train)\n",
    "    np.save('X_train_' + time_stamp + '.npy', X_train)\n",
    "    #np.save('y_train.npy', y_train)\n",
    "    np.save('y_train_' + time_stamp + '.npy', y_train)\n",
    "    #np.save('X_test.npy', X_test)\n",
    "    np.save('X_test_' + time_stamp + '.npy', X_test)\n",
    "    #np.save('y_test.npy', y_test)\n",
    "    np.save('y_test_' + time_stamp + '.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_combined_name = 'combined_practice1_1676255021'\n",
    "path_img_combined = folder_combined_name # from previous step\n",
    "path_img_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_npy(path_img_combined, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the whole process, jpg or png to npy\n",
    "\n",
    "To ease user effort and save time, a streamlined pipeline is provided that leverages the mp4 to jpg/npy conversion and processing functions defined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 12/12/2022\n",
    "from PIL import ImageOps # for greyscale, 4 color channel, issue \n",
    "\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_fxns_mp4_to_npy_v5 import create_folder_ifnotexist\n",
    "from utility_fxns_mp4_to_npy_v5 import convert_mp4_to_jpg\n",
    "from utility_fxns_mp4_to_npy_v5 import rename_pics\n",
    "from utility_fxns_mp4_to_npy_v5 import resize_images\n",
    "# from utility_fxns_mp4_to_npy_v1 import combine_data_sources\n",
    "from utility_fxns_mp4_to_npy_v5 import combine_data_sources_2 # needed to add path_unique into fxn code\n",
    "# from utility_fxns_mp4_to_npy_v1 import img_to_npy\n",
    "from utility_fxns_mp4_to_npy_v5 import img_to_npy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unique = './createnpy_' + str(round(time.time())) + '/'\n",
    "create_folder_ifnotexist(path_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define variables, call fxns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mp4 to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp4 to jpg\n",
    "\n",
    "mp4_folder = '../data_mp4/'\n",
    "\n",
    "mp4_files = os.listdir(mp4_folder) # if want to convert all mp4 files in a directory\n",
    "jpg_folder = mp4_files[0] + '_jpgs'\n",
    "\n",
    "label_to_prepend = '0'\n",
    "#label_to_prepend = '1'\n",
    "\n",
    "#print(mp4_folder)\n",
    "#print(mp4_files)\n",
    "#print(\" \")\n",
    "#print(jpg_folder)\n",
    "#print(label_to_prepend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_mp4_to_jpg(mp4_folder, mp4_files, jpg_folder=jpg_folder, label_to_prepend=label_to_prepend)\n",
    "convert_mp4_to_jpg(mp4_folder, mp4_files, \n",
    "                   jpg_folder=(path_unique+jpg_folder), \n",
    "                   label_to_prepend=label_to_prepend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "\n",
    "x_dim = 299\n",
    "y_dim = 299\n",
    "img_quality = 95\n",
    "\n",
    "#path_orig_img = path_unique + '1_kit.mp4_jpgs/'\n",
    "\n",
    "#path_orig_img = path_unique + '0_orig_img.mp4_jpgs/'\n",
    "path_orig_img = path_unique + '1_orig_img.mp4_jpgs/'\n",
    "\n",
    "path_smaller_img = path_orig_img[:-1] + '_' + str(x_dim) + '/'\n",
    "path_smaller_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_images(path_orig_img, path_smaller_img, x_dim, y_dim, img_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_source = ['0_orig_img.mp4_jpgs_299/',\n",
    "             '1_orig_img.mp4_jpgs_299/'\n",
    "            ]\n",
    "\n",
    "\n",
    "# ls_files_cnt = [5856,5320]\n",
    "ls_files_cnt = [1000,1000]\n",
    "\n",
    "folder_combined = 'data_combined_all_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_combined_name = combine_data_sources_2(ls_source, \n",
    "                                            ls_files_cnt, \n",
    "                                            folder_combined, path_unique\n",
    "                                            )\n",
    "folder_combined_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### jpg to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#folder_combined_name = './data_combined'\n",
    "path_img_combined = path_unique + folder_combined_name # from previous step\n",
    "path_img_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_npy_2(path_img_combined, 0.80, path_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
